{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\RouteMate\\yolo\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.199  Python-3.9.13 torch-1.8.0+cu111 CUDA:0 (NVIDIA GeForce 920MX, 2048MiB)\n",
      "WARNING  Upgrade to torch>=2.0.0 for deterministic training.\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=D:\\RouteMate\\data.yaml, epochs=3, patience=50, batch=1, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train4, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train4\n",
      "Overriding model.yaml nc=80 with nc=29\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    756967  ultralytics.nn.modules.head.Detect           [29, [64, 128, 256]]          \n",
      "Model summary: 225 layers, 3016503 parameters, 3016487 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\RouteMate\\train\\labels.cache... 109701 images, 0 backgrounds, 0 corrupt: 100%|██████████| 109701/109701 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\RouteMate\\train\\images\\MP_KSC_002414.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\RouteMate\\train\\images\\MP_KSC_008223.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\RouteMate\\train\\images\\MP_KSC_013711.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\RouteMate\\train\\images\\MP_KSC_019377.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\RouteMate\\train\\images\\MP_KSC_019378.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\RouteMate\\train\\images\\MP_KSC_019379.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\RouteMate\\train\\images\\MP_KSC_019380.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\RouteMate\\train\\images\\MP_KSC_021671.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\RouteMate\\train\\images\\MP_KSC_021740.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\RouteMate\\train\\images\\MP_KSC_022342.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\RouteMate\\train\\images\\MP_KSC_022396.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\RouteMate\\train\\images\\MP_KSC_022401.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\RouteMate\\train\\images\\MP_SEL_000231.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\RouteMate\\train\\images\\MP_SEL_001512.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\RouteMate\\train\\images\\MP_SEL_005259.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\RouteMate\\train\\images\\MP_SEL_007214.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\RouteMate\\train\\images\\MP_SEL_008382.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\RouteMate\\train\\images\\MP_SEL_008657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\RouteMate\\train\\images\\MP_SEL_010268.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\RouteMate\\train\\images\\MP_SEL_011766.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\RouteMate\\train\\images\\MP_SEL_017485.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\RouteMate\\train\\images\\MP_SEL_018950.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\RouteMate\\train\\images\\MP_SEL_024380.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\RouteMate\\train\\images\\MP_SEL_025153.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\RouteMate\\train\\images\\MP_SEL_028691.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\RouteMate\\train\\images\\MP_SEL_028695.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\RouteMate\\train\\images\\MP_SEL_032104.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\RouteMate\\train\\images\\MP_SEL_039570.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\RouteMate\\train\\images\\MP_SEL_042876.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\RouteMate\\train\\images\\MP_SEL_043595.jpg: 5 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\RouteMate\\train\\images\\MP_SEL_050296.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\RouteMate\\train\\images\\MP_SEL_052303.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\RouteMate\\train\\images\\MP_SEL_052398.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\RouteMate\\train\\images\\MP_SEL_054046.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\RouteMate\\train\\images\\MP_SEL_056324.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\RouteMate\\train\\images\\MP_SEL_057032.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\RouteMate\\train\\images\\MP_SEL_059814.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\RouteMate\\train\\images\\MP_SEL_065973.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\RouteMate\\train\\images\\MP_SEL_065991.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\RouteMate\\train\\images\\MP_SEL_077014.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\RouteMate\\val\\labels.cache... 27425 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27425/27425 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  D:\\RouteMate\\val\\images\\MP_SEL_093184.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  D:\\RouteMate\\val\\images\\MP_SEL_098152.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  D:\\RouteMate\\val\\images\\MP_SEL_100447.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  D:\\RouteMate\\val\\images\\MP_SEL_100618.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  D:\\RouteMate\\val\\images\\MP_SEL_100639.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  D:\\RouteMate\\val\\images\\MP_SEL_105450.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  D:\\RouteMate\\val\\images\\MP_SEL_108627.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  D:\\RouteMate\\val\\images\\MP_SEL_114233.jpg: 1 duplicate labels removed\n",
      "Plotting labels to runs\\detect\\train4\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000303, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train4\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/3     0.258G      1.642       2.01      1.267         14        640: 100%|██████████| 109701/109701 [15:33:41<00:00,  1.96it/s]  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13713/13713 [30:56<00:00,  7.39it/s]\n",
      "                   all      27425     281090      0.477      0.238      0.248      0.148\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/3     0.537G      1.508      1.465      1.197         10        640: 100%|██████████| 109701/109701 [16:29:29<00:00,  1.85it/s]    \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13713/13713 [30:57<00:00,  7.38it/s]\n",
      "                   all      27425     281090      0.478      0.253      0.274      0.165\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/3     0.533G      1.457       1.36      1.169         27        640: 100%|██████████| 109701/109701 [15:06:00<00:00,  2.02it/s]  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13713/13713 [31:16<00:00,  7.31it/s]\n",
      "                   all      27425     281090      0.489      0.262      0.286      0.173\n",
      "\n",
      "3 epochs completed in 48.712 hours.\n",
      "Optimizer stripped from runs\\detect\\train4\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from runs\\detect\\train4\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating runs\\detect\\train4\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.0.199  Python-3.9.13 torch-1.8.0+cu111 CUDA:0 (NVIDIA GeForce 920MX, 2048MiB)\n",
      "Model summary (fused): 168 layers, 3011303 parameters, 0 gradients, 8.1 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13713/13713 [29:41<00:00,  7.70it/s]\n",
      "                   all      27425     281090      0.488      0.262      0.287      0.173\n",
      "               bicycle      27425       4373      0.398      0.593      0.491      0.273\n",
      "                   bus      27425       4273      0.592      0.541      0.568      0.392\n",
      "                   car      27425      66541      0.717      0.835      0.861      0.632\n",
      "               carrier      27425        797     0.0536   0.000202     0.0208    0.00978\n",
      "                   cat      27425          7          0          0          0          0\n",
      "                   dog      27425         40          0          0          0          0\n",
      "            motorcycle      27425       4921      0.604      0.544      0.554      0.299\n",
      "       movable_signage      27425      12212      0.559        0.5       0.52      0.341\n",
      "                person      27425      38770      0.797      0.614      0.713      0.426\n",
      "               scooter      27425         93          1          0          0          0\n",
      "              stroller      27425        146          1          0     0.0275     0.0159\n",
      "                 truck      27425      11476      0.598      0.538       0.59      0.406\n",
      "            wheelchair      27425         78          0          0          0          0\n",
      "             barricade      27425       1733      0.428      0.019     0.0567     0.0367\n",
      "                 bench      27425       1577      0.336      0.219      0.186      0.109\n",
      "               bollard      27425      27276      0.719      0.445      0.521      0.293\n",
      "                 chair      27425       2346      0.246      0.371       0.24      0.115\n",
      "          fire_hydrant      27425        819          1    0.00561      0.105     0.0647\n",
      "                 kiosk      27425        986          1          0     0.0692      0.043\n",
      "         parking_meter      27425         45          0          0          0          0\n",
      "                  pole      27425      32883      0.736      0.563      0.685      0.416\n",
      "          potted_plant      27425       6911      0.444      0.429      0.403      0.213\n",
      "      power_controller      27425          1          0          0          0          0\n",
      "                  stop      27425       1375      0.458      0.168      0.197      0.115\n",
      "                 table      27425        741      0.554     0.0216     0.0902     0.0406\n",
      "         traffic_light      27425      12769      0.583      0.277      0.329      0.158\n",
      "traffic_light_controller      27425          2          0          0          0          0\n",
      "          traffic_sign      27425      14701      0.591      0.347      0.389      0.237\n",
      "            tree_trunk      27425      33198      0.748      0.574      0.692      0.387\n",
      "Speed: 1.1ms preprocess, 52.6ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train4\u001b[0m\n",
      "Ultralytics YOLOv8.0.199  Python-3.9.13 torch-1.8.0+cu111 CUDA:0 (NVIDIA GeForce 920MX, 2048MiB)\n",
      "Model summary (fused): 168 layers, 3011303 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'runs\\detect\\train4\\weights\\best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 33, 8400) (6.0 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['onnx>=1.12.0'] not found, attempting AutoUpdate...\n",
      "Collecting onnx>=1.12.0\n",
      "  Downloading onnx-1.14.1-cp39-cp39-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy in d:\\routemate\\yolo\\lib\\site-packages (from onnx>=1.12.0) (1.26.1)\n",
      "Collecting protobuf>=3.20.2 (from onnx>=1.12.0)\n",
      "  Downloading protobuf-4.24.4-cp39-cp39-win_amd64.whl.metadata (540 bytes)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in d:\\routemate\\yolo\\lib\\site-packages (from onnx>=1.12.0) (4.8.0)\n",
      "Downloading onnx-1.14.1-cp39-cp39-win_amd64.whl (13.3 MB)\n",
      "   ---------------------------------------- 13.3/13.3 MB 29.7 MB/s eta 0:00:00\n",
      "Downloading protobuf-4.24.4-cp39-cp39-win_amd64.whl (430 kB)\n",
      "   ---------------------------------------- 430.5/430.5 kB ? eta 0:00:00\n",
      "Installing collected packages: protobuf, onnx\n",
      "Successfully installed onnx-1.14.1 protobuf-4.24.4\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success  19.4s, installed 1 package: ['onnx>=1.12.0']\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m  \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.14.1 opset 12...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  24.1s, saved as 'runs\\detect\\train4\\weights\\best.onnx' (11.7 MB)\n",
      "\n",
      "Export complete (24.8s)\n",
      "Results saved to \u001b[1mD:\\RouteMate\\runs\\detect\\train4\\weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=runs\\detect\\train4\\weights\\best.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=runs\\detect\\train4\\weights\\best.onnx imgsz=640 data=D:\\RouteMate\\data.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    }
   ],
   "source": [
    "# Load a pretrained YOLO model (recommended for training)\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Train the model for 3 epochs\n",
    "results = model.train(data='D:\\\\RouteMate\\\\data.yaml', epochs=3, batch=1, imgsz=640, device=0)\n",
    "\n",
    "# Export the model to ONNX format\n",
    "success = model.export(format='onnx')\n",
    "\n",
    "# Evaluate the model's performance on the validation set\n",
    "results = model.val()\n",
    "\n",
    "# Perform object detection on an image using the model\n",
    "results = model(source=source, imgsz=640)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.199  Python-3.9.13 torch-1.8.0+cu111 CUDA:0 (NVIDIA GeForce 920MX, 2048MiB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\RouteMate\\val\\labels.cache... 27425 images, 0 backgrounds, 0 corrupt: 100%|██████████| 27425/27425 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  D:\\RouteMate\\val\\images\\MP_SEL_093184.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  D:\\RouteMate\\val\\images\\MP_SEL_098152.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  D:\\RouteMate\\val\\images\\MP_SEL_100447.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  D:\\RouteMate\\val\\images\\MP_SEL_100618.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  D:\\RouteMate\\val\\images\\MP_SEL_100639.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  D:\\RouteMate\\val\\images\\MP_SEL_105450.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  D:\\RouteMate\\val\\images\\MP_SEL_108627.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  D:\\RouteMate\\val\\images\\MP_SEL_114233.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27425/27425 [38:53<00:00, 11.75it/s]\n",
      "                   all      27425     281090      0.489      0.262      0.287      0.173\n",
      "               bicycle      27425       4373      0.398      0.593      0.491      0.273\n",
      "                   bus      27425       4273      0.594      0.541      0.568      0.392\n",
      "                   car      27425      66541      0.717      0.835      0.861      0.632\n",
      "               carrier      27425        797     0.0759   0.000286     0.0208    0.00975\n",
      "                   cat      27425          7          0          0          0          0\n",
      "                   dog      27425         40          0          0          0          0\n",
      "            motorcycle      27425       4921      0.605      0.544      0.554        0.3\n",
      "       movable_signage      27425      12212      0.558        0.5       0.52      0.342\n",
      "                person      27425      38770      0.797      0.614      0.714      0.427\n",
      "               scooter      27425         93          1          0          0          0\n",
      "              stroller      27425        146          1          0     0.0275      0.016\n",
      "                 truck      27425      11476      0.597      0.537       0.59      0.407\n",
      "            wheelchair      27425         78          0          0          0          0\n",
      "             barricade      27425       1733      0.426      0.019     0.0567     0.0367\n",
      "                 bench      27425       1577      0.334      0.219      0.186      0.108\n",
      "               bollard      27425      27276      0.723      0.446      0.523      0.295\n",
      "                 chair      27425       2346      0.246      0.371       0.24      0.115\n",
      "          fire_hydrant      27425        819          1    0.00561      0.105     0.0649\n",
      "                 kiosk      27425        986          1          0     0.0693     0.0431\n",
      "         parking_meter      27425         45          0          0          0          0\n",
      "                  pole      27425      32883      0.738      0.564      0.687      0.417\n",
      "          potted_plant      27425       6911      0.443      0.429      0.403      0.213\n",
      "      power_controller      27425          1          0          0          0          0\n",
      "                  stop      27425       1375      0.459      0.168      0.197      0.114\n",
      "                 table      27425        741      0.554     0.0216     0.0898     0.0404\n",
      "         traffic_light      27425      12769      0.582      0.277      0.329      0.159\n",
      "traffic_light_controller      27425          2          0          0          0          0\n",
      "          traffic_sign      27425      14701      0.592      0.347      0.389      0.238\n",
      "            tree_trunk      27425      33198      0.748      0.574      0.693      0.388\n",
      "Speed: 1.4ms preprocess, 66.0ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train42\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "metrics = model.val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 D:\\RouteMate\\test\\images\\MP_SEL_116118.jpg: 384x640 1 person, 1 pole, 3 traffic_signs, 173.6ms\n",
      "Speed: 5.0ms preprocess, 173.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 0.5854318737983704 0.5026564598083496 0.10577259212732315 0.9946870803833008\n",
      "27 0.8885616660118103 0.34270864725112915 0.03045043908059597 0.049704913049936295\n",
      "8 0.44511309266090393 0.5236301422119141 0.021856307983398438 0.10105235129594803\n",
      "27 0.8883129954338074 0.39098095893859863 0.03291931375861168 0.04537929967045784\n",
      "27 0.48718467354774475 0.08926582336425781 0.09336443245410919 0.1608743518590927\n"
     ]
    }
   ],
   "source": [
    "# Define a glob search for all JPG files in a directory\n",
    "source = r'D:\\\\RouteMate\\\\test\\\\images\\\\MP_SEL_116118.jpg'\n",
    "# source = r'D:\\\\RouteMate\\\\test\\\\images\\\\*.jpg'\n",
    "\n",
    "# Run batched inference on a list of images\n",
    "results = model(source, stream=True)  # return a list of Results objects\n",
    "\n",
    "# Process results list\n",
    "for result in results:\n",
    "    boxes = result.boxes\n",
    "    for i, label in enumerate(boxes.cls):\n",
    "        x_pos = float(boxes.xywhn[i][0])\n",
    "        y_pos = float(boxes.xywhn[i][1])\n",
    "        width = float(boxes.xywhn[i][2])\n",
    "        height = float(boxes.xywhn[i][3])\n",
    "        print(int(label), x_pos, y_pos, width, height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A class for storing and manipulating inference results.\n",
    "   \n",
    "Args:   \n",
    "    orig_img (numpy.ndarray): The original image as a numpy array.   \n",
    "    path (str): The path to the image file.   \n",
    "    names (dict): A dictionary of class names.   \n",
    "    boxes (torch.tensor, optional): A 2D tensor of bounding box coordinates for each detection.   \n",
    "    masks (torch.tensor, optional): A 3D tensor of detection masks, where each mask is a binary image.   \n",
    "    probs (torch.tensor, optional): A 1D tensor of probabilities of each class for classification task.   \n",
    "    keypoints (List[List[float]], optional): A list of detected keypoints for each object.   \n",
    "   \n",
    "Attributes:\n",
    "    orig_img (numpy.ndarray): The original image as a numpy array.   \n",
    "    orig_shape (tuple): The original image shape in (height, width) format.   \n",
    "    **boxes (Boxes, optional): A Boxes object containing the detection bounding boxes.**   \n",
    "    masks (Masks, optional): A Masks object containing the detection masks.   \n",
    "    probs (Probs, optional): A Probs object containing probabilities of each class for classification task.   \n",
    "    keypoints (Keypoints, optional): A Keypoints object containing detected keypoints for each object.   \n",
    "    speed (dict): A dictionary of preprocess, inference, and postprocess speeds in milliseconds per image.   \n",
    "    names (dict): A dictionary of class names.   \n",
    "    path (str): The path to the image file.   \n",
    "    _keys (tuple): A tuple of attribute names for non-empty attributes.   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
